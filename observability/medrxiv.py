"""The preprint server for health sciences."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_medrxiv.ipynb.

# %% auto 0
__all__ = ['url', 'response', 'soup', 'items', 'data', 'filepath', 'new_data']

# %% ../nbs/01_medrxiv.ipynb 3
import warnings
warnings.filterwarnings("ignore")

import os

import pandas as pd
import requests
from bs4 import BeautifulSoup

# %% ../nbs/01_medrxiv.ipynb 5
url = "https://connect.medrxiv.org/medrxiv_xml.php?subject=all"
response = requests.get(url)
response.raise_for_status()

# %% ../nbs/01_medrxiv.ipynb 6
soup = BeautifulSoup(response.content, "lxml-xml")
items = soup.find_all("item")

# %% ../nbs/01_medrxiv.ipynb 7
data = []
for item in items:
    item_data = {}
    for child in item.find_all(recursive=False):
        tag_name = child.name
        tag_value = child.text.strip() if child.text else None
        item_data[tag_name] = tag_value
    item_data.update(item.attrs)
    data.append(item_data)
data[0]

# %% ../nbs/01_medrxiv.ipynb 8
filepath = "../data/medrxiv.json"
os.makedirs(os.path.dirname(filepath), exist_ok=True)

new_data = pd.DataFrame(data)
if os.path.exists(filepath):
    existing_data = pd.read_json(filepath, lines=True)
    combined_data = pd.concat([existing_data, new_data])
else:
    combined_data = new_data

combined_data.drop_duplicates(subset="identifier").to_json(filepath, orient="records", lines=True)
print(os.path.abspath(filepath))
